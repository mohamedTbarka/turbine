//! gRPC service implementation

use crate::state::{ServerState, WorkflowState, WorkflowType};
use std::collections::HashMap;
use std::pin::Pin;
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::mpsc;
use tokio_stream::wrappers::ReceiverStream;
use tokio_stream::Stream;
use tonic::{Request, Response, Status};
use tracing::{debug, error, info};
use turbine_backend::Backend;
use turbine_broker::Broker;
use turbine_core::{Message, Serializer, Task, TaskId, TaskMeta, TaskOptions, TaskResult, TaskState};

// Include generated protobuf code
// In a real build, this would be generated by tonic-build
// For now, we'll define the types manually since we can't run the build script

/// Task state enum for proto
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
#[repr(i32)]
pub enum ProtoTaskState {
    Unspecified = 0,
    Pending = 1,
    Received = 2,
    Running = 3,
    Success = 4,
    Failure = 5,
    Retry = 6,
    Revoked = 7,
}

impl From<TaskState> for ProtoTaskState {
    fn from(state: TaskState) -> Self {
        match state {
            TaskState::Pending => ProtoTaskState::Pending,
            TaskState::Received => ProtoTaskState::Received,
            TaskState::Running => ProtoTaskState::Running,
            TaskState::Success => ProtoTaskState::Success,
            TaskState::Failure => ProtoTaskState::Failure,
            TaskState::Retry => ProtoTaskState::Retry,
            TaskState::Revoked => ProtoTaskState::Revoked,
        }
    }
}

impl From<ProtoTaskState> for i32 {
    fn from(state: ProtoTaskState) -> Self {
        state as i32
    }
}

/// Turbine service implementation
#[derive(Clone)]
pub struct TurbineServiceImpl {
    pub state: Arc<ServerState>,
}

impl TurbineServiceImpl {
    /// Create a new service instance
    pub fn new(state: Arc<ServerState>) -> Self {
        Self { state }
    }

    /// Submit a task
    pub async fn submit_task(
        &self,
        name: String,
        args: Vec<serde_json::Value>,
        kwargs: HashMap<String, serde_json::Value>,
        options: TaskOptions,
        task_id: Option<String>,
        correlation_id: Option<String>,
    ) -> Result<(String, TaskState), Status> {
        // Create task
        let id = task_id.map(TaskId::from).unwrap_or_else(TaskId::new);
        let mut task = Task::with_id(id.clone(), name);
        task.args = args;
        task.kwargs = kwargs;
        task.options = options.clone();
        task.correlation_id = correlation_id;

        // Create message
        let message = Message::from_task(task, Serializer::MessagePack)
            .map_err(|e| Status::internal(format!("Failed to create message: {}", e)))?;

        // Publish to broker
        self.state
            .broker
            .publish(&options.queue, &message)
            .await
            .map_err(|e| Status::internal(format!("Failed to publish task: {}", e)))?;

        // Store initial metadata
        let meta = TaskMeta::new();
        self.state
            .backend
            .store_meta(&id, &meta)
            .await
            .map_err(|e| Status::internal(format!("Failed to store metadata: {}", e)))?;

        info!("Submitted task {} to queue {}", id, options.queue);

        Ok((id.to_string(), TaskState::Pending))
    }

    /// Get task status
    pub async fn get_task_status(&self, task_id: &str) -> Result<Option<TaskMeta>, Status> {
        let id = TaskId::from(task_id);
        self.state
            .backend
            .get_meta(&id)
            .await
            .map_err(|e| Status::internal(format!("Failed to get task status: {}", e)))
    }

    /// Get task result
    pub async fn get_task_result(&self, task_id: &str) -> Result<Option<TaskResult>, Status> {
        let id = TaskId::from(task_id);
        self.state
            .backend
            .get_result(&id)
            .await
            .map_err(|e| Status::internal(format!("Failed to get task result: {}", e)))
    }

    /// Wait for task result
    pub async fn wait_for_result(
        &self,
        task_id: &str,
        timeout_secs: u64,
    ) -> Result<Option<TaskResult>, Status> {
        let id = TaskId::from(task_id);
        let timeout = Duration::from_secs(timeout_secs.max(1).min(300)); // 1-300 seconds

        self.state
            .backend
            .wait_for_result(&id, timeout, Duration::from_millis(100))
            .await
            .map_err(|e| Status::internal(format!("Failed to wait for result: {}", e)))
    }

    /// Revoke a task
    pub async fn revoke_task(&self, task_id: &str) -> Result<bool, Status> {
        let id = TaskId::from(task_id);

        // Try to revoke in broker
        let revoked = self
            .state
            .broker
            .revoke("default", &id)
            .await
            .map_err(|e| Status::internal(format!("Failed to revoke task: {}", e)))?;

        // Update state in backend
        if revoked {
            self.state
                .backend
                .update_state(&id, TaskState::Revoked)
                .await
                .map_err(|e| Status::internal(format!("Failed to update state: {}", e)))?;
        }

        info!("Revoked task {}: {}", task_id, revoked);
        Ok(revoked)
    }

    /// Get queue info
    pub async fn get_queue_info(&self, queue: Option<&str>) -> Result<Vec<QueueInfo>, Status> {
        let queues = match queue {
            Some(q) => vec![q.to_string()],
            None => vec!["default".to_string()], // TODO: track all queues
        };

        let mut infos = Vec::new();
        for queue_name in queues {
            let pending = self
                .state
                .broker
                .queue_length(&queue_name)
                .await
                .unwrap_or(0);

            infos.push(QueueInfo {
                name: queue_name,
                pending: pending as u64,
                processing: 0, // TODO: track processing
                consumers: 0,  // TODO: track consumers
                throughput: 0.0,
            });
        }

        Ok(infos)
    }

    /// Purge a queue
    pub async fn purge_queue(&self, queue: &str) -> Result<u64, Status> {
        let purged = self
            .state
            .broker
            .purge(queue)
            .await
            .map_err(|e| Status::internal(format!("Failed to purge queue: {}", e)))?;

        info!("Purged {} messages from queue {}", purged, queue);
        Ok(purged as u64)
    }

    /// Health check
    pub async fn health_check(&self) -> HealthStatus {
        let broker_ok = self.state.broker_healthy().await;
        let backend_ok = self.state.backend_healthy().await;

        HealthStatus {
            status: if broker_ok && backend_ok {
                "healthy"
            } else {
                "unhealthy"
            }
            .to_string(),
            version: env!("CARGO_PKG_VERSION").to_string(),
            uptime: self.state.uptime(),
            broker_status: if broker_ok { "connected" } else { "disconnected" }.to_string(),
            backend_status: if backend_ok { "connected" } else { "disconnected" }.to_string(),
        }
    }

    /// Submit a chain of tasks
    pub async fn submit_chain(
        &self,
        tasks: Vec<(String, Vec<serde_json::Value>, HashMap<String, serde_json::Value>, TaskOptions)>,
        stop_on_failure: bool,
    ) -> Result<(String, Vec<String>), Status> {
        let workflow_id = uuid::Uuid::new_v4().to_string();
        let mut task_ids = Vec::new();

        // Create tasks with proper parent-child relationships
        let mut previous_id: Option<TaskId> = None;

        for (name, args, kwargs, mut options) in tasks {
            let task_id = TaskId::new();
            let mut task = Task::with_id(task_id.clone(), name);
            task.args = args;
            task.kwargs = kwargs;
            task.root_id = Some(TaskId::from(workflow_id.clone()));

            if let Some(prev) = previous_id.take() {
                task.parent_id = Some(prev);
            }

            // Add workflow metadata to headers
            options.headers.insert("workflow_id".to_string(), workflow_id.clone());
            options.headers.insert("workflow_type".to_string(), "chain".to_string());
            options
                .headers
                .insert("stop_on_failure".to_string(), stop_on_failure.to_string());

            task.options = options.clone();

            // Only publish the first task immediately
            // Subsequent tasks will be published by workers
            if task_ids.is_empty() {
                let message = Message::from_task(task.clone(), Serializer::MessagePack)
                    .map_err(|e| Status::internal(format!("Failed to create message: {}", e)))?;

                self.state
                    .broker
                    .publish(&options.queue, &message)
                    .await
                    .map_err(|e| Status::internal(format!("Failed to publish task: {}", e)))?;
            }

            task_ids.push(task_id.to_string());
            previous_id = Some(task_id);
        }

        // Store workflow state
        {
            let mut workflows = self.state.workflows.write().await;
            workflows.insert(
                workflow_id.clone(),
                WorkflowState::new(workflow_id.clone(), WorkflowType::Chain, task_ids.clone()),
            );
        }

        info!("Submitted chain workflow {} with {} tasks", workflow_id, task_ids.len());
        Ok((workflow_id, task_ids))
    }

    /// Submit a group of parallel tasks
    pub async fn submit_group(
        &self,
        tasks: Vec<(String, Vec<serde_json::Value>, HashMap<String, serde_json::Value>, TaskOptions)>,
    ) -> Result<(String, Vec<String>), Status> {
        let workflow_id = uuid::Uuid::new_v4().to_string();
        let mut task_ids = Vec::new();

        for (name, args, kwargs, mut options) in tasks {
            let task_id = TaskId::new();
            let mut task = Task::with_id(task_id.clone(), name);
            task.args = args;
            task.kwargs = kwargs;
            task.root_id = Some(TaskId::from(workflow_id.clone()));
            task.parent_id = Some(TaskId::from(workflow_id.clone()));

            options.headers.insert("workflow_id".to_string(), workflow_id.clone());
            options.headers.insert("workflow_type".to_string(), "group".to_string());

            task.options = options.clone();

            let message = Message::from_task(task, Serializer::MessagePack)
                .map_err(|e| Status::internal(format!("Failed to create message: {}", e)))?;

            self.state
                .broker
                .publish(&options.queue, &message)
                .await
                .map_err(|e| Status::internal(format!("Failed to publish task: {}", e)))?;

            task_ids.push(task_id.to_string());
        }

        // Store workflow state
        {
            let mut workflows = self.state.workflows.write().await;
            workflows.insert(
                workflow_id.clone(),
                WorkflowState::new(workflow_id.clone(), WorkflowType::Group, task_ids.clone()),
            );
        }

        info!("Submitted group workflow {} with {} tasks", workflow_id, task_ids.len());
        Ok((workflow_id, task_ids))
    }

    /// Get workflow status
    pub async fn get_workflow_status(&self, workflow_id: &str) -> Result<Option<WorkflowState>, Status> {
        let workflows = self.state.workflows.read().await;
        Ok(workflows.get(workflow_id).cloned())
    }
}

/// Queue information
#[derive(Debug, Clone)]
pub struct QueueInfo {
    pub name: String,
    pub pending: u64,
    pub processing: u64,
    pub consumers: u32,
    pub throughput: f64,
}

/// Health status
#[derive(Debug, Clone)]
pub struct HealthStatus {
    pub status: String,
    pub version: String,
    pub uptime: u64,
    pub broker_status: String,
    pub backend_status: String,
}
